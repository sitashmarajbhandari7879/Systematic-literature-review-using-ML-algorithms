{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0d0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import math\n",
    "punctuations = '''!()-[]{};:'\"\\,\\n<>./?@#$%^&*_~'''\n",
    "path = 'C:/Users/sitas/OneDrive/Desktop/Python/Master thesis/research_papers/*.txt'    \n",
    "files=glob.glob(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e93375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document -  1 :\n",
      "In addition to the variables considered in the aforementioned studies other variables including land fragmentation access to ready market use of fertilizer pesticides and improved seeds as well as farming in particular agroecological zones may also infuence technical efciency Tis study analyses Ghanaâ€™s maize farm level technical efciency variations caused by the aforementioned factors \n",
      "\n",
      "TERMS -> TERM FREQ -> NORM TERM FREQ  (term freq/ doc size)  \n",
      "\n",
      "including  ->  1  ->  1 / 54\n",
      "market  ->  1  ->  1 / 54\n",
      "by  ->  1  ->  1 / 54\n",
      "factors  ->  1  ->  1 / 54\n",
      "fertilizer  ->  1  ->  1 / 54\n",
      "and  ->  1  ->  1 / 54\n",
      "may  ->  1  ->  1 / 54\n",
      "use  ->  1  ->  1 / 54\n",
      "also  ->  1  ->  1 / 54\n",
      "analyses  ->  1  ->  1 / 54\n",
      "seeds  ->  1  ->  1 / 54\n",
      "improved  ->  1  ->  1 / 54\n",
      "of  ->  1  ->  1 / 54\n",
      "technical  ->  2  ->  2 / 54\n",
      "to  ->  2  ->  2 / 54\n",
      "In  ->  1  ->  1 / 54\n",
      "variables  ->  2  ->  2 / 54\n",
      "fragmentation  ->  1  ->  1 / 54\n",
      "efciency  ->  2  ->  2 / 54\n",
      "aforementioned  ->  2  ->  2 / 54\n",
      "studies  ->  1  ->  1 / 54\n",
      "agroecological  ->  1  ->  1 / 54\n",
      "in  ->  2  ->  2 / 54\n",
      "pesticides  ->  1  ->  1 / 54\n",
      "ready  ->  1  ->  1 / 54\n",
      "considered  ->  1  ->  1 / 54\n",
      "land  ->  1  ->  1 / 54\n",
      "addition  ->  1  ->  1 / 54\n",
      "access  ->  1  ->  1 / 54\n",
      "the  ->  3  ->  3 / 54\n",
      "well  ->  1  ->  1 / 54\n",
      "maize  ->  1  ->  1 / 54\n",
      "as  ->  2  ->  2 / 54\n",
      "Tis  ->  1  ->  1 / 54\n",
      "level  ->  1  ->  1 / 54\n",
      "farming  ->  1  ->  1 / 54\n",
      "Ghanaâ€™s  ->  1  ->  1 / 54\n",
      "study  ->  1  ->  1 / 54\n",
      "farm  ->  1  ->  1 / 54\n",
      "caused  ->  1  ->  1 / 54\n",
      "particular  ->  1  ->  1 / 54\n",
      "variations  ->  1  ->  1 / 54\n",
      "other  ->  1  ->  1 / 54\n",
      "zones  ->  1  ->  1 / 54\n",
      "infuence  ->  1  ->  1 / 54\n",
      "\n",
      "|| d1 || =  0.1593023197600486\n",
      "\n",
      "\n",
      "Document -  2 :\n",
      "Whether or not maize farmers are technically efcient determines their choice of productivity improvement strategy and very important for achieving the sustainable development goals on no poverty and zero hunger  \n",
      "\n",
      "TERMS -> TERM FREQ -> NORM TERM FREQ  (term freq/ doc size)  \n",
      "\n",
      "  ->  1  ->  1 / 31\n",
      "improvement  ->  1  ->  1 / 31\n",
      "choice  ->  1  ->  1 / 31\n",
      "and  ->  2  ->  2 / 31\n",
      "technically  ->  1  ->  1 / 31\n",
      "hunger  ->  1  ->  1 / 31\n",
      "of  ->  1  ->  1 / 31\n",
      "strategy  ->  1  ->  1 / 31\n",
      "efcient  ->  1  ->  1 / 31\n",
      "development  ->  1  ->  1 / 31\n",
      "sustainable  ->  1  ->  1 / 31\n",
      "no  ->  1  ->  1 / 31\n",
      "goals  ->  1  ->  1 / 31\n",
      "their  ->  1  ->  1 / 31\n",
      "on  ->  1  ->  1 / 31\n",
      "Whether  ->  1  ->  1 / 31\n",
      "important  ->  1  ->  1 / 31\n",
      "for  ->  1  ->  1 / 31\n",
      "the  ->  1  ->  1 / 31\n",
      "maize  ->  1  ->  1 / 31\n",
      "zero  ->  1  ->  1 / 31\n",
      "farmers  ->  1  ->  1 / 31\n",
      "determines  ->  1  ->  1 / 31\n",
      "poverty  ->  1  ->  1 / 31\n",
      "not  ->  1  ->  1 / 31\n",
      "productivity  ->  1  ->  1 / 31\n",
      "very  ->  1  ->  1 / 31\n",
      "achieving  ->  1  ->  1 / 31\n",
      "are  ->  1  ->  1 / 31\n",
      "or  ->  1  ->  1 / 31\n",
      "\n",
      "|| d2 || =  0.18530847246896867\n",
      "\n",
      "\n",
      "Document -  3 :\n",
      "Virtually all of the growth in human population in the next generation is projected to be in cities Given the environmental stresses on the planet today it is critically important that these new urban areas have little or no negative impacts A comprehensive assessment of these impacts will include all operational factors â€“ energy water food and transportation â€“ as well as all the embodied consequences of construction and maintenance \n",
      "\n",
      "TERMS -> TERM FREQ -> NORM TERM FREQ  (term freq/ doc size)  \n",
      "\n",
      "generation  ->  1  ->  1 / 70\n",
      "critically  ->  1  ->  1 / 70\n",
      "maintenance  ->  1  ->  1 / 70\n",
      "impacts  ->  2  ->  2 / 70\n",
      "will  ->  1  ->  1 / 70\n",
      "factors  ->  1  ->  1 / 70\n",
      "and  ->  2  ->  2 / 70\n",
      "new  ->  1  ->  1 / 70\n",
      "water  ->  1  ->  1 / 70\n",
      "A  ->  1  ->  1 / 70\n",
      "assessment  ->  1  ->  1 / 70\n",
      "cities  ->  1  ->  1 / 70\n",
      "of  ->  3  ->  3 / 70\n",
      "projected  ->  1  ->  1 / 70\n",
      "consequences  ->  1  ->  1 / 70\n",
      "urban  ->  1  ->  1 / 70\n",
      "to  ->  1  ->  1 / 70\n",
      "areas  ->  1  ->  1 / 70\n",
      "construction  ->  1  ->  1 / 70\n",
      "no  ->  1  ->  1 / 70\n",
      "food  ->  1  ->  1 / 70\n",
      "comprehensive  ->  1  ->  1 / 70\n",
      "in  ->  3  ->  3 / 70\n",
      "growth  ->  1  ->  1 / 70\n",
      "all  ->  3  ->  3 / 70\n",
      "next  ->  1  ->  1 / 70\n",
      "these  ->  2  ->  2 / 70\n",
      "operational  ->  1  ->  1 / 70\n",
      "transportation  ->  1  ->  1 / 70\n",
      "environmental  ->  1  ->  1 / 70\n",
      "on  ->  1  ->  1 / 70\n",
      "human  ->  1  ->  1 / 70\n",
      "important  ->  1  ->  1 / 70\n",
      "embodied  ->  1  ->  1 / 70\n",
      "energy  ->  1  ->  1 / 70\n",
      "Given  ->  1  ->  1 / 70\n",
      "the  ->  5  ->  5 / 70\n",
      "well  ->  1  ->  1 / 70\n",
      "as  ->  2  ->  2 / 70\n",
      "include  ->  1  ->  1 / 70\n",
      "little  ->  1  ->  1 / 70\n",
      "stresses  ->  1  ->  1 / 70\n",
      "is  ->  2  ->  2 / 70\n",
      "have  ->  1  ->  1 / 70\n",
      "that  ->  1  ->  1 / 70\n",
      "â€“  ->  2  ->  2 / 70\n",
      "it  ->  1  ->  1 / 70\n",
      "planet  ->  1  ->  1 / 70\n",
      "negative  ->  1  ->  1 / 70\n",
      "today  ->  1  ->  1 / 70\n",
      "be  ->  1  ->  1 / 70\n",
      "or  ->  1  ->  1 / 70\n",
      "Virtually  ->  1  ->  1 / 70\n",
      "population  ->  1  ->  1 / 70\n",
      "\n",
      "|| d3 || =  0.1564921592871903\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "Documents_dict = {}\n",
    "vocab_dict = {}   \n",
    "for file in files:     \n",
    "    f=open(file, 'r')\n",
    "    text = f.read()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    final_text = \"\"\n",
    "    for char in text:\n",
    "        if char not in punctuations:\n",
    "            final_text = final_text + char\n",
    "    list_text = final_text.split(\" \")\n",
    "    \n",
    "    for word in list_text:\n",
    "        if word in vocab_dict.keys():\n",
    "            vocab_dict[word] = vocab_dict[word] + 1\n",
    "        else:\n",
    "            vocab_dict[word] = 1\n",
    "            \n",
    "    Length_text = len(list_text)\n",
    "    uniq_set = set(list_text)\n",
    "    uniq_text = (list(uniq_set))\n",
    "    \n",
    "    print(\"Document - \", count, \":\")\n",
    "    \n",
    "    print(final_text, \"\\n\")\n",
    "    \n",
    "    TF_dict = {}\n",
    "    print(\"TERMS\", \"->\", \"TERM FREQ\", \"->\", \"NORM TERM FREQ  (term freq/ doc size) \", \"\\n\")\n",
    "    norm_doc = 0;\n",
    "    for words in uniq_text:\n",
    "        print(words, \" -> \", list_text.count(words), \" -> \", list_text.count(words), \"/\",Length_text)\n",
    "        list_temp = [list_text.count(words), list_text.count(words)/Length_text]\n",
    "        TF_dict[words] = list_temp\n",
    "        norm_doc = norm_doc + TF_dict[words][1]*TF_dict[words][1]\n",
    "        \n",
    "    norm_docc = math.sqrt(norm_doc)\n",
    "    TF_dict[\"norm_doc\"+str(count)] = norm_docc\n",
    "    print(\"\\n|| d\"+str(count)+\" || = \", norm_docc)\n",
    "    Documents_dict[\"doc\"+str(count)] = TF_dict\n",
    "    print(\"\\n\")\n",
    "    f.close()\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ffe930",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_vocab = []\n",
    "uniq_vocab = []\n",
    "for word in vocab_dict.keys():\n",
    "    if vocab_dict[word] > 2:\n",
    "        freq_vocab.append(word)\n",
    "    elif vocab_dict[word] == 1:\n",
    "        uniq_vocab.append(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "508bef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High frequency words : ['to', 'the', 'in', 'of', 'and', 'as', 'all']\n",
      "Rare words: ['In', 'addition', 'considered', 'studies', 'other', 'including', 'land', 'fragmentation', 'access', 'ready', 'market', 'use', 'fertilizer', 'pesticides', 'improved', 'seeds', 'farming', 'particular', 'agroecological', 'zones', 'may', 'also', 'infuence', 'Tis', 'study', 'analyses', 'Ghanaâ€™s', 'farm', 'level', 'variations', 'caused', 'by', 'Whether', 'not', 'farmers', 'are', 'technically', 'efcient', 'determines', 'their', 'choice', 'productivity', 'improvement', 'strategy', 'very', 'for', 'achieving', 'sustainable', 'development', 'goals', 'poverty', 'zero', 'hunger', '', 'Virtually', 'growth', 'human', 'population', 'next', 'generation', 'projected', 'be', 'cities', 'Given', 'environmental', 'stresses', 'planet', 'today', 'it', 'critically', 'that', 'new', 'urban', 'areas', 'have', 'little', 'negative', 'A', 'comprehensive', 'assessment', 'will', 'include', 'operational', 'energy', 'water', 'food', 'transportation', 'embodied', 'consequences', 'construction', 'maintenance']\n"
     ]
    }
   ],
   "source": [
    "print(\"High frequency words :\",freq_vocab)\n",
    "print(\"Rare words:\",uniq_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0483ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query:poverty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['poverty']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input(\"Enter the query:\")\n",
    "query = query.split(\" \")\n",
    "query_list = list(set(query))\n",
    "query_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a438dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TERMS -> DOC FREQ -> NORM DOC FREQ  (doc freq/total doc freq)\n",
      "\n",
      "poverty -> 1 -> 1.0\n",
      "\n",
      "|| q || =  1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "Query_doc_freq = {}\n",
    "Total_doc_freq = 0\n",
    "while i<len(query_list):\n",
    "    doc_freq = 0\n",
    "    j=1\n",
    "    while j<=count:\n",
    "        if query_list[i] in Documents_dict[\"doc\"+str(j)].keys():\n",
    "            doc_freq = doc_freq + 1\n",
    "        j=j+1\n",
    "        \n",
    "    Total_doc_freq = Total_doc_freq + doc_freq\n",
    "    Query_doc_freq[query_list[i]] = doc_freq\n",
    "    i = i+1\n",
    "    \n",
    "if Total_doc_freq == 0:\n",
    "    print(\"--------Query not found--------\")\n",
    "else:\n",
    "    print(\"\\n\\nTERMS\", \"->\", \"DOC FREQ\", \"->\", \"NORM DOC FREQ  (doc freq/total doc freq)\\n\")\n",
    "    norm_q = 0\n",
    "    for Keyss in Query_doc_freq:\n",
    "        print(Keyss, \"->\", Query_doc_freq[Keyss], \"->\", Query_doc_freq[Keyss]/Total_doc_freq)\n",
    "        Query_doc_freq[Keyss] = Query_doc_freq[Keyss]/Total_doc_freq\n",
    "        norm_q = norm_q + Query_doc_freq[Keyss]*Query_doc_freq[Keyss]\n",
    "    norm_qq = math.sqrt(norm_q)\n",
    "    print(\"\\n|| q || = \", norm_qq, \"\\n\")\n",
    "    Similarity_scores = {}\n",
    "    i=1\n",
    "    while i<= count:\n",
    "        sim_temp = 0\n",
    "        j=0\n",
    "        while j<len(query_list):\n",
    "            if query_list[j] in Documents_dict[\"doc\"+str(i)].keys():\n",
    "                sim_temp = sim_temp + Documents_dict[\"doc\"+str(i)][query_list[j]][1]*Query_doc_freq[query_list[j]]\n",
    "            j=j+1\n",
    "        denominator = norm_qq*Documents_dict[\"doc\"+str(i)][\"norm_doc\"+str(i)]\n",
    "        Similarity_scores[\"doc\"+str(i)] = sim_temp/denominator\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e407ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores: {'doc1': 0.0, 'doc2': 0.17407765595569782, 'doc3': 0.0}\n",
      "\n",
      "Ranking based on similarity scores: \n",
      "[('doc2', 0.17407765595569782), ('doc1', 0.0), ('doc3', 0.0)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # print(vocab_dict)\n",
    "    print(\"Similarity scores:\", Similarity_scores)\n",
    "\n",
    "    print(\"\\nRanking based on similarity scores: \")\n",
    "    print (sorted(Similarity_scores.items(), reverse=True, key = lambda x : x[1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21d9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
